[2025-01-12 08:27:07 +0000] [65046] [INFO] Starting gunicorn 23.0.0
[2025-01-12 08:27:07 +0000] [65046] [INFO] Listening at: http://0.0.0.0:58090 (65046)
[2025-01-12 08:27:07 +0000] [65046] [INFO] Using worker: sync
[2025-01-12 08:27:07 +0000] [65051] [INFO] Booting worker with pid: 65051
[2025-01-12 08:27:07 +0000] [65052] [INFO] Booting worker with pid: 65052
[2025-01-12 08:27:07 +0000] [65056] [INFO] Booting worker with pid: 65056
[2025-01-12 08:27:07 +0000] [65057] [INFO] Booting worker with pid: 65057
[2025-01-12 08:27:16,373] [ WARNING] easyocr.py:80 - Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.
[2025-01-12 08:27:16,403] [ WARNING] easyocr.py:80 - Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.
[2025-01-12 08:27:16,507] [ WARNING] easyocr.py:80 - Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.
[2025-01-12 08:27:16,659] [ WARNING] easyocr.py:80 - Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.
[2025-01-12 08:27:23 +0000] [65046] [INFO] Handling signal: int
[2025-01-12 08:27:23 +0000] [65051] [INFO] Worker exiting (pid: 65051)
[2025-01-12 08:27:23 +0000] [65056] [INFO] Worker exiting (pid: 65056)
[2025-01-12 08:27:23 +0000] [65057] [INFO] Worker exiting (pid: 65057)
[2025-01-12 08:27:23 +0000] [65052] [INFO] Worker exiting (pid: 65052)
[2025-01-12 08:27:24 +0000] [65046] [ERROR] Worker (pid:65051) was sent SIGINT!
[2025-01-12 08:27:24 +0000] [65046] [ERROR] Worker (pid:65052) was sent SIGINT!
[2025-01-12 08:27:24 +0000] [65046] [ERROR] Worker (pid:65057) was sent SIGINT!
[2025-01-12 08:27:24 +0000] [65046] [ERROR] Worker (pid:65056) was sent SIGINT!
[2025-01-12 08:27:24 +0000] [65046] [INFO] Shutting down: Master
[2025-01-12 08:27:34 +0000] [65632] [INFO] Starting gunicorn 23.0.0
[2025-01-12 08:27:34 +0000] [65632] [INFO] Listening at: http://0.0.0.0:58090 (65632)
[2025-01-12 08:27:34 +0000] [65632] [INFO] Using worker: sync
[2025-01-12 08:27:34 +0000] [65633] [INFO] Booting worker with pid: 65633
[2025-01-12 08:27:42,388] [ WARNING] easyocr.py:80 - Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.
Florence2LanguageForConditionalGeneration has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`. From ðŸ‘‰v4.50ðŸ‘ˆ onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.
  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes
  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).
  - If you are not the owner of the model architecture class, please contact the model code owner to update it.

image 1/1 /workspace/imgs/temp_image.png: 448x640 81 0s, 254.7ms
Speed: 7.6ms preprocess, 254.7ms inference, 1.9ms postprocess per image at shape (1, 3, 448, 640)
no ocr bbox!!!
[2025-01-12 08:28:23 +0000] [65632] [CRITICAL] WORKER TIMEOUT (pid:65633)


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   at::_ops::linear::call(at::Tensor const&, at::Tensor const&, std::optional<at::Tensor> const&)
1   at::native::linear(at::Tensor const&, at::Tensor const&, std::optional<at::Tensor> const&)
2   at::_ops::addmm::call(at::Tensor const&, at::Tensor const&, at::Tensor const&, c10::Scalar const&, c10::Scalar const&)
3   at::native::structured_addmm_out_cpu::impl(at::Tensor const&, at::Tensor const&, at::Tensor const&, c10::Scalar const&, c10::Scalar const&, at::Tensor const&)
4   at::_ops::copy_::call(at::Tensor&, at::Tensor const&, bool)
5   at::_ops::copy_::redispatch(c10::DispatchKeySet, at::Tensor&, at::Tensor const&, bool)
6   at::native::copy_(at::Tensor&, at::Tensor const&, bool)
7   at::TensorIteratorBase::for_each(c10::function_ref<void (char**, long const*, long, long)>, long)
8   at::TensorIteratorBase::serial_for_each(c10::function_ref<void (char**, long const*, long, long)>, at::Range) const

----------------------
Error Message Summary:
----------------------
FatalError: `Process abort signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1736670503 (unix time) try "date -d @1736670503" if you are using GNU date ***]
  [SignalInfo: *** SIGABRT (@0x10060) received by PID 65633 (TID 0x7fc5f1af5740) from PID 65632 ***]

[2025-01-12 08:28:23 +0000] [65632] [ERROR] Worker (pid:65633) was sent SIGABRT!
[2025-01-12 08:28:23 +0000] [66457] [INFO] Booting worker with pid: 66457
[2025-01-12 08:28:32,157] [ WARNING] easyocr.py:80 - Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.
Florence2LanguageForConditionalGeneration has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`. From ðŸ‘‰v4.50ðŸ‘ˆ onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.
  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes
  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).
  - If you are not the owner of the model architecture class, please contact the model code owner to update it.
[2025-01-12 08:29:12 +0000] [65632] [INFO] Handling signal: int
[2025-01-12 08:29:12 +0000] [66457] [INFO] Worker exiting (pid: 66457)
[2025-01-12 08:29:12 +0000] [65632] [ERROR] Worker (pid:66457) was sent SIGINT!
[2025-01-12 08:29:12 +0000] [65632] [INFO] Shutting down: Master
[2025-01-12 08:30:59 +0000] [68249] [INFO] Starting gunicorn 23.0.0
[2025-01-12 08:30:59 +0000] [68249] [INFO] Listening at: http://0.0.0.0:58090 (68249)
[2025-01-12 08:30:59 +0000] [68249] [INFO] Using worker: sync
[2025-01-12 08:30:59 +0000] [68250] [INFO] Booting worker with pid: 68250
[2025-01-12 08:31:07,487] [ WARNING] easyocr.py:80 - Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.
Florence2LanguageForConditionalGeneration has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`. From ðŸ‘‰v4.50ðŸ‘ˆ onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.
  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes
  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).
  - If you are not the owner of the model architecture class, please contact the model code owner to update it.
[2025-01-12 08:31:58 +0000] [68249] [INFO] Handling signal: int
[2025-01-12 08:31:58 +0000] [68250] [INFO] Worker exiting (pid: 68250)
[2025-01-12 08:31:58 +0000] [68249] [ERROR] Worker (pid:68250) was sent SIGINT!
[2025-01-12 08:31:58 +0000] [68249] [INFO] Shutting down: Master
[2025-01-12 08:32:10 +0000] [69124] [INFO] Starting gunicorn 23.0.0
[2025-01-12 08:32:10 +0000] [69124] [INFO] Listening at: http://0.0.0.0:58090 (69124)
[2025-01-12 08:32:10 +0000] [69124] [INFO] Using worker: gthread
[2025-01-12 08:32:10 +0000] [69132] [INFO] Booting worker with pid: 69132
[2025-01-12 08:32:18,669] [ WARNING] easyocr.py:80 - Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.
Florence2LanguageForConditionalGeneration has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`. From ðŸ‘‰v4.50ðŸ‘ˆ onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.
  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes
  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).
  - If you are not the owner of the model architecture class, please contact the model code owner to update it.

image 1/1 /workspace/imgs/temp_image.png: 448x640 81 0s, 436.4ms
Speed: 5.4ms preprocess, 436.4ms inference, 2.7ms postprocess per image at shape (1, 3, 448, 640)
no ocr bbox!!!
127.0.0.1 - - [12/Jan/2025:08:34:41 +0000] "POST /process_image HTTP/1.1" 200 1729 "-" "curl/7.81.0"
